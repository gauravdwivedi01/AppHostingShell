sax-config :
   env-config :
      activemq: 
               password: "admin"
               stomp.connection.url: "localhost:61613"
               host: "localhost:61616"
               username: "admin"
      storm: 
               nimbus: 
                        host: "localhost"
                        thrift.port: "6627"
                        ui.port: "9090"
                        seeds: ""
                        ha.enabled: "false"
               impersonation: 
                        enabled: "false"
                        target.user: ""
               spout.zk.port: "2181"
               cluster.manager: "standalone"
               supervisors.servers: ""
               yarn: 
                        resource.manager.host: "localhost"
                        resource.manager.port: "8088"
               spout.zk.servers: "localhost"
               ui.host: "localhost"
      clusterconfig: 
               spark.version: "spark2"
               manager: 
                        type: "ambari"
                        url: "http://172.26.65.19:8080"
                        username: "admin"
                        password: "admin"
                        clustername: "HDP2_6"
      jdbc: 
               password: ""
               driver: "org.hsqldb.jdbc.JDBCDriver"
               url: "jdbc:hsqldb:hsql://localhost:9001/saxhsqldb"
               username: "SA"
      kerberos: 
               dfs.namenode.kerberos.principal: "nn/_HOST@REALM"
               krb.config.override: "true"
               dfs.core.site.location: ""
               hbase.master.kerberos.principal: "hbase/_HOST@REALM"
               yarn.resourcemanager.kerberos.principal: "rm/_HOST@REALM"
               hbase.regionserver.kerberos.principal: "hbase/_HOST@REALM"
               hive.metastore.kerberos.principal: "hive/_HOST@REALM"
               hive.hiveserver2.kerberos.principal: "hive/_HOST@REALM"
      graphite: 
               port: "2003"
               host: "localhost"
               ui.port: "8080"
      rabbitmq: 
               password: "guest"
               port: "5672"
               stompUrl: "http://localhost:15674/stomp"
               host: "localhost:5672"
               virtualHost: "/"
               username: "guest"
               web.url: "http://localhost:15672"
      system-config: 
               authentication.source: "db"
               hive: 
                        metaStoreURI: "thrift://impetus-i0339.impetus.co.in:9083"
                        hiveServer2: "jdbc:hive2://impetus-i0339.impetus.co.in:10000/default"
                        hiveServer2Password: ""
               sax.ui.host: "localhost"
               elasticsearch: 
                        cluster.name: "sax_es_cluster"
                        connect: "localhost:9300"
                        http.connect: "localhost:9200"
                        embedded.data.dir: "/tmp/eDataDir"
                        embedded.http.enabled: "true"
                        embedded.node.name: "sax_es_node"
                        embedded.data.enabled: "true"
                        embedded.local.enabled: "false"
                        httpPort: "9200"
                        shield.enabled: "false"
                        shield.password.access.enabled: "false"
                        shield.user.name: "elastic"
                        shield.user.password: "changeme"
                        shield.hostname.resolvename: "false"
                        shield.hostname.verification: "false"
                        shield.http.ssl: "false"
                        shield.keystore.enabled: "false"
                        shield.ssl.certificate.verification: "false"
                        shield.ssl.enabled: "false"
                        shield.ssl.hostname_verification: "false"
                        shield.ssl.hostname_verification.resolve_name: "false"
                        shield.truststore.enabled: "false"
                        shield.transport.ssl: "false"
                        shield.ssl.keystore.key_password: ""
                        shield.ssl.keystore.password: ""
                        shield.ssl.keystore.path: ""
                        shield.ssl.truststore.password: ""
                        shield.ssl.truststore.path: ""
               solr: 
                        zk.hosts: "impetus-i0338.impetus.co.in:2181,impetus-i0339.impetus.co.in:2181,impetus-i0340.impetus.co.in:2181/solr"
                        config.version: "5.2.1"
               rmq: 
                        exchangeName: "selfTestExchange"
                        queueName: "selfTestQueue"
                        status.exchangeName: "pushStatusExchange"
                        status.queueName: "pushStatusQueue"
               hadoop: 
                        ha.enabled: "false"
                        hdfs.uri: "hdfs://impetus-i0338.impetus.co.in:8020"
                        hdfs.user: "hdfs"
                        dfs.nameservices: ""
                        dfs.namenode1.details: ""
                        dfs.namenode2.details: ""
               sax.installation.dir: "/home/impadmin/Downloads/sax315/StreamAnalytix/"
               hbase: 
                        zk.hosts: "impetus-i0340.impetus.co.in,impetus-i0338.impetus.co.in,impetus-i0339.impetus.co.in"
                        zk.port: "2181"
                        client.retries.number: "1"
                        zk.parent.node: "/hbase-unsecure"
                        zk.recovery.retry: "1"
               ingestion.type: "0"
               logmonitoring.ui.port: "8090"
               sax.web.url: "http://localhost:8090/StreamAnalytix"
               oozie: 
                        server.url: "http://impetus-i0340.impetus.co.in:11000/oozie"
                        libPath: "/user/oozie/share/lib"
                        namenodeUri: "hdfs://impetus-i0338.impetus.co.in:8020"
                        jobtrackerURL: "impetus-i0339.impetus.co.in:8032"
                        workflowNotificationURL: "/workflow/ackWorkflowStatus/${tenantId}/$jobId/$status"
                        actionNotificationURL: "/workflow/ackWorkflowActionStatus/${tenantId}/$jobId/$nodeName/$status"
                        coordinatorActionNotificationURL: "/workflow/ackWorkflowActionStatus/${tenantId}/$jobId/$actionId/$status"
               authorization.source: "db"
               sax.monitoring.reporters.supported: "rabbitmq"
               index: 
                        type: "elasticsearch"
                        replication.factor: "2"
                        isbatch.enable: "false"
                        batch.size: "1"
                        across.field.search.enabled: "true"
                        noofshards: "2"
                        routing.required: "false"
                        source: "true"
                        retries: "5"
                        retries.interval.ms: "3000"
                        ttl.insec: "259200"
               sax.ui.port: "8090"
               components.supported: "rabbitmq,activemq,kafka,hbase,cassandra,solr,elasticsearch,hdfs,hiveEmitter"
               messaging.type: "RABBITMQ"
               logmonitoring.ui.host: "localhost"
               cassandra: 
                        hosts: "localhost:9042"
                        username: "cassandra"
                        password: "cassandra"
                        thrift.client.retries: "5"
                        thrift.client.retries.interval.ms: "5000"
                        keyspace.replication.factor: "1"
                        keyspace.replication.strategy: "org.apache.cassandra.locator.SimpleStrategy"
                        connection.retries: "1"
               database.dialect: "hypersql"
               kafka: 
                        metadata.broker.list: "impetus-i0338.impetus.co.in:6667,impetus-i0340.impetus.co.in:6667,impetus-i0344.impetus.co.in:6667"
                        zk.servers: "impetus-i0339.impetus.co.in:2181,impetus-i0338.impetus.co.in:2181,impetus-i0340.impetus.co.in:2181"
                        topic.administration: "false"
               persistence: 
                        store: "hbase"
                        isbatch.enable: "false"
                        batch.size: "1"
                        compression: "false"
               superuser.authentication.source: "db"
               sax.metric.server: "ambari"
      zk: 
               hosts: "impetus-i0338.impetus.co.in:2181,impetus-i0339.impetus.co.in:2181,impetus-i0340.impetus.co.in:2181"
      activiti: 
               alert.email.charset: "UTF-8"
               alert.email.html: ""
               alert.email.from: "BDappTest@server-020.impetus.co.in"
               jdbc: 
                        driver: "org.postgresql.Driver"
                        url: "jdbc:postgresql://localhost:5432/activiti"
                        username: "postgres"
                        password: "postgres"
               mailserver: 
                        host: "server-020.impetus.co.in"
                        port: "25"
                        username: "BDappTest@server-020.impetus.co.in"
                        password: "9c-qxGJy"
                        default.from: "BDappTest@server-020.impetus.co.in"
                        ssl.enabled: "false"
                        tsl.enabled: "false"
               history: "none"
               db: "postgresql"
      spark: 
               livy.url: "http://localhost:8998"
               home: "/usr/hdp/2.4.2.0-258/spark"
               master: "spark://localhost:7077"
               cluster.manager: "yarn"
               jobServer.logDir: "/home/job-server/spark-jobserver-latest/spark-jobserver-0.6.2/sax"
               ui.port: "8080"
               history.server: "impetus-i0340.impetus.co.in:18081"
               hadoop: 
                        isHDP: "true"
               yarn: 
                        resource.manager.host: "impetus-i0339.impetus.co.in"
                        resource.manager.webapp.port: "8088"
                        proxy.server.port: "8088"
                        resource.manager.port: "8032"
                        resource.manager.isHA: "false"
                        resource.manager.ha.address.names: "rm1,rm2"
                        resource.manager.ha.address.hosts: "localhost1:8032,localhost2:8032"
               job.submit.mode: "spark-submit"
               ui.host: "localhost"
               jobserver.spark.home: "/home/spark-1.6.1-bin-hadoop2.6/"
               jobServer.url: "localhost:8092"
               rest.master: "localhost:6066"
      ldap: 
               password: "ldap"
               groupSearchBase: "ou=Groups,o=streamanalytix"
               userSearchBase: "ou=People,o=streamanalytix"
               userSearchFilter: "uid={0}"
               groupSearchFilter: "(member={0})"
               groupname: 
                        admin.role: ""
                        developer.role: ""
                        devops.role: ""
                        tier2.role: ""
               url: "ldap://localhost:10389"
               userDn: "cn=Manager,o=streamanalytix"
      couchbase: 
               maxpoolsize: "1"
               defaultbucket.memorysize: "500"
               password: "Administrator"
               defaultbucket.replicano: "1"
               port: "8091/pools"
               host: "localhost"
               http.url: "http://"
               bucketlist: "CDR:CDR"
               params: 
                        com.streamanalytix.storm.bolt.SampleBolt: "CDR"
               polling.timeout: "120000"
               polling.sleeptime: "2000"
               username: "Administrator"
      ambari: 
               collector.port: "6188"
               collector.host: "impetus-i0339.impetus.co.in"
      intellicus: 
               superadmin.password: "Admin"
               reportClientPath: "common/dashboard-int/ReportClient.properties"
               sax.connName: "Conn_SAX"
               sax.orgId: "Org_SAX"
               superadmin.userid: "Admin"
               superadmin.organization: "Intellica"
               sax.url: "http://localhost/intellicus"
